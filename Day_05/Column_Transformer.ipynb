{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4635d13-16f3-41f3-8114-bf13ed834dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.compose import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.pipeline import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.linear_model import *\n",
    "import os\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a65dd270-21f6-4e61-bcc4-3414447c8898",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Change directory to the dataset location\n",
    "os.chdir(r\"D:\\Datasets\")\n",
    "\n",
    "# Read the CSV data\n",
    "df = pd.read_csv(\"Housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b91eef8-f856-4417-acae-0eb98164d7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['driveway_no', 'driveway_yes', 'recroom_no', 'recroom_yes',\n",
      "       'fullbase_no', 'fullbase_yes', 'gashw_no', 'gashw_yes', 'airco_no',\n",
      "       'airco_yes', 'prefarea_no', 'prefarea_yes', 'price', 'lotsize',\n",
      "       'bedrooms', 'bathrms', 'stories', 'garagepl'],\n",
      "      dtype='object')\n",
      "Index(['price', 'lotsize', 'bedrooms', 'bathrms', 'stories', 'garagepl',\n",
      "       'driveway_yes', 'recroom_yes', 'fullbase_yes', 'gashw_yes', 'airco_yes',\n",
      "       'prefarea_yes'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "ohc = OneHotEncoder(sparse_output=False).set_output(transform='pandas')\n",
    "\n",
    "ct = make_column_transformer((ohc,['driveway','recroom','fullbase','gashw','airco','prefarea',]),\n",
    "                             ('passthrough',['price','lotsize','bedrooms','bathrms','stories','garagepl']),verbose_feature_names_out=False)\n",
    "\n",
    "'''This line creates a ColumnTransformer object, which applies different transformations to different columns of a DataFrame.\n",
    "The first argument is a tuple of transformations to apply to specific columns. \n",
    "In this case, the OneHotEncoder is applied to the columns 'driveway', 'recroom', 'fullbase', 'gashw', 'airco', and 'prefarea'.\n",
    "The second argument is another tuple of transformations to apply to specific columns. \n",
    "In this case, the columns 'price', 'lotsize', 'bedrooms', 'bathrms', 'stories', and 'garagepl' are left unchanged (i.e., \"passed through\")'''\n",
    "\n",
    "# This line sets the output format of the ColumnTransformer to pandas DataFrame for easier handling.\n",
    "ct = ct.set_output(transform='pandas') \n",
    "\n",
    "# This line fits the ColumnTransformer to the DataFrame df and applies the transformations\n",
    "dum_df_1 = ct.fit_transform(df)\n",
    "\n",
    "# This line prints the columns of the transformed DataFrame.\n",
    "print(dum_df_1.columns)\n",
    "\n",
    "# This line creates a new DataFrame dum_df_2 by converting categorical variables in df into binary columns using the get_dummies function\n",
    "dum_df_2 = pd.get_dummies(df,drop_first=True)\n",
    "\n",
    "# This line prints the columns of the new DataFrame.\n",
    "print(dum_df_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "730c8b46-6b32-49c8-be6c-b3f1c7ecebc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['lotsize', 'bedrooms', 'bathrms', 'stories', 'garagepl', 'recroom_yes',\n",
      "       'fullbase_yes'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- airco_yes\n- driveway_yes\n- gashw_yes\n- prefarea_yes\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m dum_df_2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(tst,drop_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(dum_df_2\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m---> 19\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m.\u001b[39mpredict(dum_df_2)\n",
      "File \u001b[1;32mC:\\annaconda\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:419\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    418\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 419\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    421\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32mC:\\annaconda\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:400\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    397\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    398\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 400\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    401\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[1;32mC:\\annaconda\\Lib\\site-packages\\sklearn\\base.py:548\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    484\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    485\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    490\u001b[0m ):\n\u001b[0;32m    491\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \n\u001b[0;32m    493\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 548\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    551\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    552\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    553\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    554\u001b[0m         )\n",
      "File \u001b[1;32mC:\\annaconda\\Lib\\site-packages\\sklearn\\base.py:481\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    477\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    479\u001b[0m     )\n\u001b[1;32m--> 481\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- airco_yes\n- driveway_yes\n- gashw_yes\n- prefarea_yes\n"
     ]
    }
   ],
   "source": [
    "# This line removes the 'price' column from the DataFrame dum_df_2 and assigns the result to x\n",
    "x=dum_df_2.drop('price',axis=1)\n",
    "\n",
    "# This line assigns the 'price' column from dum_df_2 to y\n",
    "y=dum_df_2['price']\n",
    "\n",
    "# This line creates an instance of the LogisticRegression class, which is a type of machine learning model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# This line trains the LogisticRegression model on the data in x and y\n",
    "lr.fit(x,y)\n",
    "\n",
    "\n",
    "####unlabeled data\n",
    "\n",
    "tst = pd.read_csv('tst_Housing.csv')  #taking same dataset but different rown or columns for getting error(sir give this mismatched data)\n",
    "dum_df_2 = pd.get_dummies(tst,drop_first=True)\n",
    "print(dum_df_2.columns)\n",
    "y_pred = lr.predict(dum_df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d5f6ab-0cfb-4714-bb9e-1ca58dd71f83",
   "metadata": {},
   "source": [
    "# solving this error with OneHotEncoder and ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f58868c-2fdb-497b-b5c1-b489c24c6f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['driveway_yes', 'recroom_yes', 'fullbase_yes', 'gashw_yes', 'airco_yes',\n",
      "       'prefarea_yes', 'lotsize', 'bedrooms', 'bathrms', 'stories',\n",
      "       'garagepl'],\n",
      "      dtype='object')\n",
      "Index(['driveway_yes', 'recroom_yes', 'fullbase_yes', 'gashw_yes', 'airco_yes',\n",
      "       'prefarea_yes', 'lotsize', 'bedrooms', 'bathrms', 'stories',\n",
      "       'garagepl'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([65151.39992985, 42650.08901117, 41137.92877603, 76249.38318098])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This line creates an instance of the OneHotEncoder class, which is used to convert categorical variables into binary columns.\n",
    "# The sparse_output=False parameter ensures that the output is dense (i.e., not sparse) for easier handling.\n",
    "# The drop='first' parameter ensures that the first category in each categorical variable is not included in the new DataFrame\n",
    "ohc = OneHotEncoder(sparse_output=False,drop='first').set_output(transform='pandas')\n",
    "\n",
    "ct = make_column_transformer((ohc,make_column_selector(dtype_include=object)),\n",
    "                             ('passthrough',make_column_selector(dtype_exclude=object)),verbose_feature_names_out=False)\n",
    "\n",
    "'''This line creates a ColumnTransformer object, which applies different transformations to different columns of a DataFrame.\n",
    "The first argument is a tuple of transformations to apply to specific columns. In this case, the OneHotEncoder is applied to all columns with object (categorical) data types.\n",
    "The second argument is another tuple of transformations to apply to specific columns. In this case, all columns with non-object (numerical) data types are left unchanged (i.e., \"passed through\").\n",
    "The make_column_selector function is used to select columns based on their data types.\n",
    "The verbose_feature_names_out=False parameter suppresses verbose output about feature names.'''\n",
    "\n",
    "x = df.drop('price',axis=1)\n",
    "y=df['price']\n",
    "ct = ct.set_output(transform='pandas')\n",
    "\n",
    "# This line fits the ColumnTransformer to the DataFrame x and applies the transformations.\n",
    "x_trans = ct.fit_transform(x)  # yaha sare column pehchan liye \n",
    "print(x_trans.columns)\n",
    "\n",
    "tst = pd.read_csv('tst_Housing.csv')\n",
    "\n",
    "\n",
    "tst_trans = ct.transform(tst)  # or yaha jo columns nahi he use bana liya khudse\n",
    "print(tst_trans.columns)\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "# This line trains the LinearRegression model on the transformed training data in x_trans and y\n",
    "lr.fit(x_trans,y)\n",
    "\n",
    "# This line uses the trained LinearRegression model to predict the 'price' for each row in the transformed unlabeled data tst_trans\n",
    "y_pred = lr.predict(tst_trans)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc88375b-3925-4370-8370-5e354bf1af81",
   "metadata": {},
   "source": [
    "# Conclusion: both the sets(x_trans & tst_trans) column schemas are same "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5361c67f-4154-4f5b-b978-ddf791c4d1e5",
   "metadata": {},
   "source": [
    "# solving this problem using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f7cc8b9-69b4-449e-b224-9d7a1ab8bc19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([65151.39992985, 42650.08901117, 41137.92877603, 76249.38318098])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('TRNS',ct),('LR',lr)])\n",
    "pipe.fit(x,y)\n",
    "y_pred = pipe.predict(tst)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018acb34-2970-4146-9aff-6b78a0670fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
