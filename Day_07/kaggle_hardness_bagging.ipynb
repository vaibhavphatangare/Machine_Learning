{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "601f57a0-89d2-4e24-b1a4-e7b21a8ef539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <th>density_Total</th>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <th>val_e_Average</th>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <th>zaratio_Average</th>\n",
       "      <th>density_Average</th>\n",
       "      <th>Hardness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.841611</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>20.612526</td>\n",
       "      <td>11.088100</td>\n",
       "      <td>2.766000</td>\n",
       "      <td>1.732000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.496070</td>\n",
       "      <td>0.91457</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>7.558488</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>20.298893</td>\n",
       "      <td>12.040830</td>\n",
       "      <td>2.755000</td>\n",
       "      <td>1.631000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.492719</td>\n",
       "      <td>0.71760</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.0</td>\n",
       "      <td>8.885992</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>33.739258</td>\n",
       "      <td>12.086300</td>\n",
       "      <td>2.828000</td>\n",
       "      <td>1.788000</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.481478</td>\n",
       "      <td>1.50633</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>8.795296</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>20.213349</td>\n",
       "      <td>10.948500</td>\n",
       "      <td>2.648000</td>\n",
       "      <td>1.626000</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.489272</td>\n",
       "      <td>0.78937</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116.0</td>\n",
       "      <td>9.577996</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>24.988133</td>\n",
       "      <td>11.824480</td>\n",
       "      <td>2.766000</td>\n",
       "      <td>1.682000</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.492736</td>\n",
       "      <td>1.86481</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10402</th>\n",
       "      <td>128.0</td>\n",
       "      <td>7.558488</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>26.385218</td>\n",
       "      <td>11.330440</td>\n",
       "      <td>2.644000</td>\n",
       "      <td>1.631000</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.496070</td>\n",
       "      <td>1.79607</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10403</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1.743160</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>20.766935</td>\n",
       "      <td>14.163933</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>1.556667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.480390</td>\n",
       "      <td>0.81480</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10404</th>\n",
       "      <td>196.0</td>\n",
       "      <td>30.920000</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>53.490297</td>\n",
       "      <td>10.074300</td>\n",
       "      <td>2.295000</td>\n",
       "      <td>1.545000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>0.469715</td>\n",
       "      <td>2.11540</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10405</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.553160</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>26.621687</td>\n",
       "      <td>11.290033</td>\n",
       "      <td>2.743333</td>\n",
       "      <td>1.756667</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.486507</td>\n",
       "      <td>0.77755</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10406</th>\n",
       "      <td>288.0</td>\n",
       "      <td>24.655328</td>\n",
       "      <td>11.142857</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>22.536126</td>\n",
       "      <td>10.960357</td>\n",
       "      <td>2.792143</td>\n",
       "      <td>1.772857</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.493919</td>\n",
       "      <td>0.97737</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10407 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       allelectrons_Total  density_Total  allelectrons_Average  val_e_Average  \\\n",
       "id                                                                              \n",
       "0                   100.0       0.841611             10.000000       4.800000   \n",
       "1                   100.0       7.558488             10.000000       4.800000   \n",
       "2                    76.0       8.885992             15.600000       5.600000   \n",
       "3                   100.0       8.795296             10.000000       4.800000   \n",
       "4                   116.0       9.577996             11.600000       4.800000   \n",
       "...                   ...            ...                   ...            ...   \n",
       "10402               128.0       7.558488             12.000000       4.000000   \n",
       "10403                30.0       1.743160             10.000000       5.333333   \n",
       "10404               196.0      30.920000             24.500000       5.500000   \n",
       "10405                38.0       1.553160             12.666667       4.666667   \n",
       "10406               288.0      24.655328             11.142857       4.571429   \n",
       "\n",
       "       atomicweight_Average  ionenergy_Average  el_neg_chi_Average  \\\n",
       "id                                                                   \n",
       "0                 20.612526          11.088100            2.766000   \n",
       "1                 20.298893          12.040830            2.755000   \n",
       "2                 33.739258          12.086300            2.828000   \n",
       "3                 20.213349          10.948500            2.648000   \n",
       "4                 24.988133          11.824480            2.766000   \n",
       "...                     ...                ...                 ...   \n",
       "10402             26.385218          11.330440            2.644000   \n",
       "10403             20.766935          14.163933            3.090000   \n",
       "10404             53.490297          10.074300            2.295000   \n",
       "10405             26.621687          11.290033            2.743333   \n",
       "10406             22.536126          10.960357            2.792143   \n",
       "\n",
       "       R_vdw_element_Average  R_cov_element_Average  zaratio_Average  \\\n",
       "id                                                                     \n",
       "0                   1.732000               0.860000         0.496070   \n",
       "1                   1.631000               0.910000         0.492719   \n",
       "2                   1.788000               0.864000         0.481478   \n",
       "3                   1.626000               0.936000         0.489272   \n",
       "4                   1.682000               0.896000         0.492736   \n",
       "...                      ...                    ...              ...   \n",
       "10402               1.631000               0.892000         0.496070   \n",
       "10403               1.556667               0.866667         0.480390   \n",
       "10404               1.545000               1.120000         0.469715   \n",
       "10405               1.756667               0.980000         0.486507   \n",
       "10406               1.772857               0.940000         0.493919   \n",
       "\n",
       "       density_Average  Hardness  \n",
       "id                                \n",
       "0              0.91457       6.0  \n",
       "1              0.71760       6.5  \n",
       "2              1.50633       2.5  \n",
       "3              0.78937       6.0  \n",
       "4              1.86481       6.0  \n",
       "...                ...       ...  \n",
       "10402          1.79607       4.0  \n",
       "10403          0.81480       5.0  \n",
       "10404          2.11540       1.8  \n",
       "10405          0.77755       6.0  \n",
       "10406          0.97737       6.5  \n",
       "\n",
       "[10407 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.linear_model import Ridge, LinearRegression, LogisticRegression \n",
    "from sklearn.metrics import accuracy_score,log_loss, median_absolute_error\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV,KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n",
    "from sklearn.ensemble import VotingClassifier, BaggingClassifier,BaggingRegressor\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "os.chdir('D:\\kaggla_comp\\hardness')\n",
    "\n",
    "train = pd.read_csv('train.csv',index_col=0)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dabdfdd6-2b4c-4ca8-bd80-c3da203e9274",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= train.drop('Hardness',axis=1)\n",
    "y=train['Hardness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e15563b-54c3-4afb-8767-031880bf90bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END estimator=LinearRegression(), n_estimators=10;, score=-0.978 total time=   0.0s\n",
      "[CV 2/5] END estimator=LinearRegression(), n_estimators=10;, score=-0.970 total time=   0.0s\n",
      "[CV 3/5] END estimator=LinearRegression(), n_estimators=10;, score=-0.955 total time=   0.0s\n",
      "[CV 4/5] END estimator=LinearRegression(), n_estimators=10;, score=-0.978 total time=   0.0s\n",
      "[CV 5/5] END estimator=LinearRegression(), n_estimators=10;, score=-0.928 total time=   0.0s\n",
      "[CV 1/5] END estimator=LinearRegression(), n_estimators=15;, score=-0.976 total time=   0.0s\n",
      "[CV 2/5] END estimator=LinearRegression(), n_estimators=15;, score=-0.968 total time=   0.0s\n",
      "[CV 3/5] END estimator=LinearRegression(), n_estimators=15;, score=-0.960 total time=   0.0s\n",
      "[CV 4/5] END estimator=LinearRegression(), n_estimators=15;, score=-0.980 total time=   0.0s\n",
      "[CV 5/5] END estimator=LinearRegression(), n_estimators=15;, score=-0.933 total time=   0.0s\n",
      "[CV 1/5] END estimator=Ridge(), n_estimators=10;, score=-0.978 total time=   0.0s\n",
      "[CV 2/5] END estimator=Ridge(), n_estimators=10;, score=-0.971 total time=   0.0s\n",
      "[CV 3/5] END estimator=Ridge(), n_estimators=10;, score=-0.963 total time=   0.0s\n",
      "[CV 4/5] END estimator=Ridge(), n_estimators=10;, score=-0.982 total time=   0.0s\n",
      "[CV 5/5] END estimator=Ridge(), n_estimators=10;, score=-0.932 total time=   0.0s\n",
      "[CV 1/5] END estimator=Ridge(), n_estimators=15;, score=-0.978 total time=   0.0s\n",
      "[CV 2/5] END estimator=Ridge(), n_estimators=15;, score=-0.964 total time=   0.0s\n",
      "[CV 3/5] END estimator=Ridge(), n_estimators=15;, score=-0.961 total time=   0.0s\n",
      "[CV 4/5] END estimator=Ridge(), n_estimators=15;, score=-0.980 total time=   0.0s\n",
      "[CV 5/5] END estimator=Ridge(), n_estimators=15;, score=-0.935 total time=   0.0s\n",
      "[CV 1/5] END estimator=DecisionTreeRegressor(), n_estimators=10;, score=-0.640 total time=   0.7s\n",
      "[CV 2/5] END estimator=DecisionTreeRegressor(), n_estimators=10;, score=-0.710 total time=   0.6s\n",
      "[CV 3/5] END estimator=DecisionTreeRegressor(), n_estimators=10;, score=-0.695 total time=   0.6s\n",
      "[CV 4/5] END estimator=DecisionTreeRegressor(), n_estimators=10;, score=-0.710 total time=   0.6s\n",
      "[CV 5/5] END estimator=DecisionTreeRegressor(), n_estimators=10;, score=-0.700 total time=   0.6s\n",
      "[CV 1/5] END estimator=DecisionTreeRegressor(), n_estimators=15;, score=-0.625 total time=   1.1s\n",
      "[CV 2/5] END estimator=DecisionTreeRegressor(), n_estimators=15;, score=-0.700 total time=   1.0s\n",
      "[CV 3/5] END estimator=DecisionTreeRegressor(), n_estimators=15;, score=-0.693 total time=   1.0s\n",
      "[CV 4/5] END estimator=DecisionTreeRegressor(), n_estimators=15;, score=-0.707 total time=   1.0s\n",
      "[CV 5/5] END estimator=DecisionTreeRegressor(), n_estimators=15;, score=-0.673 total time=   1.0s\n",
      "Best Parameters: {'estimator': DecisionTreeRegressor(), 'n_estimators': 15}\n",
      "Best Score: -0.6796666666666666\n"
     ]
    }
   ],
   "source": [
    "# Create a K-Fold cross-validation object with 5 splits, shuffling the data, and a random state of 24\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=24)\n",
    "\n",
    "# Create a Decision Tree Regressor\n",
    "dtr = DecisionTreeRegressor()\n",
    "\n",
    "# Create a Ridge Regression model\n",
    "ridge = Ridge()\n",
    "\n",
    "# Create a Linear Regression model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Create a Bagging Regressor using Linear Regression as the base estimator\n",
    "# Set the number of estimators to 15 and enable out-of-bag (OOB) score calculation\n",
    "bagg = BaggingRegressor(estimator=lr, n_estimators=15, random_state=24, oob_score=True)\n",
    "\n",
    "# Define the parameter grid for the Bagging Regressor\n",
    "params = {\n",
    "    'estimator': [lr, ridge, dtr],\n",
    "    'n_estimators': [10, 15]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object to perform cross-validation and hyperparameter tuning\n",
    "# Use the Bagging Regressor as the estimator, the parameter grid defined above, the K-Fold cross-validation,\n",
    "# set the verbosity to 3, and use the negative median absolute error as the scoring metric\n",
    "gcv = GridSearchCV(bagg, param_grid=params, cv=kfold, verbose=3, scoring='neg_median_absolute_error')\n",
    "\n",
    "# Fit the GridSearchCV object to the entire dataset (x and y)\n",
    "gcv.fit(x, y)\n",
    "\n",
    "# Print the best parameters found by the GridSearchCV\n",
    "print(\"Best Parameters:\", gcv.best_params_)\n",
    "\n",
    "# Print the best score (negative median absolute error) found by the GridSearchCV\n",
    "print(\"Best Score:\", gcv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8cf6036-e8f6-4dac-9273-9c2fecb2a556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__ccp_alpha': 0.0, 'estimator__criterion': 'squared_error', 'estimator__max_depth': None, 'estimator__max_features': None, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': None, 'estimator__splitter': 'best', 'estimator': DecisionTreeRegressor(), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 24, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Create a Bagging Regressor using Decision Tree Regressor as the base estimator\n",
    "# Set the random state to 24\n",
    "bagg = BaggingRegressor(estimator=dtr, random_state=24)\n",
    "\n",
    "# Print the parameters of the Bagging Regressor\n",
    "print(bagg.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78d37591-28f1-4811-8aaa-69dbddabdc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for the Bagging Regressor\n",
    "params = {\n",
    "    'estimator__max_depth': [None, 3, 5],\n",
    "    'estimator__min_samples_leaf': [1, 5, 10],\n",
    "    'estimator__min_samples_split': [2, 5, 10],\n",
    "    'n_estimators': [15, 30, 50]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object to perform cross-validation and hyperparameter tuning\n",
    "# Use the Bagging Regressor as the estimator, the parameter grid defined above, the K-Fold cross-validation,\n",
    "# set the verbosity to 3\n",
    "gcv_s = GridSearchCV(bagg, param_grid=params, cv=kfold, verbose=3)\n",
    "\n",
    "# Fit the GridSearchCV object to the entire dataset (x and y)\n",
    "gcv_s.fit(x, y)\n",
    "\n",
    "# Print the best parameters found by the GridSearchCV\n",
    "print(\"Best Parameters:\", gcv_s.best_params_)\n",
    "\n",
    "# Print the best score found by the GridSearchCV\n",
    "print(\"Best Score:\", gcv_s.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf67e844-3ab3-443c-b42f-0f393b8e2bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = gcv.best_estimator_\n",
    "\n",
    "\n",
    "test_data = pd.read_csv(\"test.csv\",index_col=0)\n",
    "\n",
    "pred_berry = best_model.predict(test_data)\n",
    "\n",
    "\n",
    "submit = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "\n",
    "submit['Hardness'] = pred_berry\n",
    "\n",
    "# Save the submission file with the predicted hardness values\n",
    "submit.to_csv(\"D:\\kaggla_comp\\hardnessbootstrap_hard_25.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e56a5b0-c7a5-4ff8-b77b-6bcfc487d7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
